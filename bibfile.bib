@article{ILSVRC15,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
doi = {10.1007/s11263-015-0816-y},
volume={115},
number={3},
pages={211-252}
}
@article{Adam21,
Author = {Adam AALAH },
Title = {Saliency analysis and visual explanations for convolutional neural networks in object detection},
note = {UVSQ, Master TRIED },
Year = {2021},
}
@article{Wyctor22,
Author = {Wyctor FOGOS DA ROCHA },
Title = {Analysis of activation and detection enhancing},
note = {UVSQ, Master TRIED },
Year = {2022},
}
@InProceedings{he2016identity,
author="He, Kaiming
and Zhang, Xiangyu
and Ren, Shaoqing
and Sun, Jian",
editor="Leibe, Bastian
and Matas, Jiri
and Sebe, Nicu
and Welling, Max",
title="Identity Mappings in Deep Residual Networks",
booktitle="Computer Vision -- ECCV 2016",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="630--645",
abstract="Deep residual networks have emerged as a family of extremely deep architectures showing compelling accuracy and nice convergence behaviors. In this paper, we analyze the propagation formulations behind the residual building blocks, which suggest that the forward and backward signals can be directly propagated from one block to any other block, when using identity mappings as the skip connections and after-addition activation. A series of ablation experiments support the importance of these identity mappings. This motivates us to propose a new residual unit, which makes training easier and improves generalization. We report improved results using a 1001-layer ResNet on CIFAR-10 (4.62Â {\%} error) and CIFAR-100, and a 200-layer ResNet on ImageNet. Code is available at: https://github.com/KaimingHe/resnet-1k-layers.",
isbn="978-3-319-46493-0"
}
@misc{simonyan2015deep,
      title={Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
      author={Karen Simonyan and Andrew Zisserman},
      year={2015},
      eprint={1409.1556},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@InProceedings{Zhou_2016_CVPR,
author = {Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
title = {Learning Deep Features for Discriminative Localization},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2016}
}

@InProceedings{Selvaraju_2017_ICCV,
author = {Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
title = {Grad-CAM: Visual Explanations From Deep Networks via Gradient-Based Localization},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
month = {Oct},
year = {2017}
}
@InProceedings{Wang_2020_CVPR_Workshops,
author = {Wang, Haofan and Wang, Zifan and Du, Mengnan and Yang, Fan and Zhang, Zijian and Ding, Sirui and Mardziel, Piotr and Hu, Xia},
title = {Score-CAM: Score-Weighted Visual Explanations for Convolutional Neural Networks},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
month = {June},
year = {2020}
}
@misc{tensorflow2015-whitepaper,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{i}n~Abadi and Ashish~Agarwal and Paul~Barham and Eugene~Brevdo and Zhifeng~Chen and Craig~Citro and Greg~S.~Corrado and Andy~Davis and Jeffrey~Dean and Matthieu~Devin and Sanjay~Ghemawat and Ian~Goodfellow and Andrew~Harp and Geoffrey~Irving and Michael~Isard and Yangqing Jia and Rafal~Jozefowicz and Lukasz~Kaiser and Manjunath~Kudlur and Josh~Levenberg and Dandelion~Man\'{e} and Rajat~Monga and Sherry~Moore and Derek~Murray and Chris~Olah and Mike~Schuster and Jonathon~Shlens and Benoit~Steiner and Ilya~Sutskever and Kunal~Talwar and Paul~Tucker and Vincent~Vanhoucke and Vijay~Vasudevan and Fernanda~Vi\'{e}gas and Oriol~Vinyals and Pete~Warden and Martin~Wattenberg and Martin~Wicke and Yuan~Yu and Xiaoqiang~Zheng},
  year={2015},
}
@manual{nvidia_cuda_guide,
  title        = {NVIDIA CUDA Programming Guide},
  organization = {NVIDIA Corporation},
  year         = {2023},
  note         = {URL: \url{https://developer.nvidia.com/cuda-zone}},
}
@online{google_colab,
  title        = {Google Colaboratory},
  organization = {Google},
  year         = {2023},
  url          = {https://colab.research.google.com},
}
@online{jupyter,
  title        = {Project Jupyter},
  organization = {Jupyter Development Team},
  year         = {2023},
  url          = {https://jupyter.org},
}
@online{vscode,
  title        = {Visual Studio Code},
  organization = {Microsoft},
  year         = {2023},
  url          = {https://code.visualstudio.com},
}
@online{KerasDoc,
    title = {Keras Documentation},
    url = {https://keras.io/api/applications/#usage-examples-for-image-classification-models},
    year         = {2023},
}
@InProceedings{Kendall_2018_CVPR,
author = {Kendall, Alex and Gal, Yarin and Cipolla, Roberto},
title = {Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}
@article{li2023fimf,
  title={FIMF score-CAM: Fast score-CAM based on local multi-feature integration for visual interpretation of CNNS},
  author={Li, Jing and Zhang, Dongbo and Meng, Bumin and Li, Yongxing and Luo, Lufeng},
  journal={IET Image Processing},
  volume={17},
  number={3},
  pages={761--772},
  year={2023},
  publisher={Wiley Online Library}
}